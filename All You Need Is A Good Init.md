# Paper

* **Title**: ALL YOU NEED IS A GOOD INIT
* **Authors**: Dmytro Mishkin, Jiri Matas
* **Link**: https://arxiv.org/abs/1511.06422
* **Tags**: Neural Network, Initialization
* **Year**: ICLR 2016

# Summary

* What
  * The paper describes an initialization method for deep sequential networks. 
  * The idea it to keep variance of layer outputs equal to one through the network. 
